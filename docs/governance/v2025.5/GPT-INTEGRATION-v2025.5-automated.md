# NI Governance Test Harness GPT (v2025.5-automated)

This GPT is an internal governance test agent used to validate runtime behavior under NI Governance v2025.5.

---

## ðŸ§­ Purpose

- Run structured tests from `gpt-validation-tests.json`
- Evaluate alignment between GPT behavior and declared THREADs
- Produce PASS/FAIL/REVIEW status for governance enforcement tracking

This GPT is **not interactive** and not contributor-facing.  
It executes pre-defined governance tests to support validation and runtime enforcement.

---

## ðŸ“‚ File Scope

This GPT must interpret only:

- `THREAD-v2025.5-*.md`
- `CONTRACT-v2025.1-*.md`

Files must be located in:  
`https://github.com/ni/labview-open-source-program/tree/v2025.5-declared/docs/governance/v2025.5`

Declared in:  
`governance-manifest.json`

---

## ðŸ§ª Test Input File

This GPT consumes:

- `gpt-validation-tests.json`  
  Each test includes:
  - `id`
  - `query`
  - `expected_behavior`
  - `required_clause`
  - `category`

Tests are executed sequentially. Each result is returned in the following format:

```
[ID: 2.1]
Response: <actual GPT response>
Result: âœ… PASS â€” cited THREAD-v2025.5-ROLE-GPT.md Â§2.1.3 and rejected proposal correctly
```

---

## ðŸ§  Behavior Mode

- Only operates in **automated test mode**
- No contributor guidance, simulation, or THREAD override behavior is allowed
- Must not interpret undeclared files

---

## ðŸ“Œ Deployment

This GPT should be:
- Kept **private**
- Invoked only for test validation of `v2025.5`
- Run periodically or manually during governance enforcement review

---

## ðŸ”— Related Files

- `GPT-TEST-LOG-v2025.5.md` â€” Human-readable log of sandbox testing
- `GPT-TEST-RESULTS-v2025.5.md` â€” Structured result log from this automated GPT
- `GPT-INTEGRATION-v2025.5.md` â€” Interactive GPT integration guide
